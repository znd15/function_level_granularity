
retry:
	/*
 * One of the few rules of preemptible RCU is that one cannot do
 * rcu_read_unlock() while holding a scheduler (or nested) lock when
 * part of the read side critical section was preemptible -- see
 * rcu_read_unlock_special().
 *
 * Since ctx->lock nests under rq->lock we must ensure the entire read
 * side critical section is non-preemptible.
 */
	preempt_disable();
	rcu_read_lock();
	ctx = rcu_dereference(task->perf_event_ctxp[ctxn]);
	if (ctx) {
		/*
 * If this context is a clone of another, it might
 * get swapped for another underneath us by
 * perf_event_task_sched_out, though the
 * rcu_read_lock() protects us from any context
 * getting freed. Lock the context and check if it
 * got swapped before we could get the lock, and retry
 * if so. If we locked the right context, then it
 * can't get swapped on us any more.
 */
		raw_spin_lock_irqsave(&ctx->lock, *flags);
		if (ctx != rcu_dereference(task->perf_event_ctxp[ctxn])) {
			raw_spin_unlock_irqrestore(&ctx->lock, *flags);
			rcu_read_unlock();
			preempt_enable();
			goto retry;
		}

		if (!atomic_inc_not_zero(&ctx->refcount)) {
			raw_spin_unlock_irqrestore(&ctx->lock, *flags);
			ctx = NULL;
		}
	}