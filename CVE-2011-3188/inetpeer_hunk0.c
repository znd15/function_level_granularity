



/*
 * INETPEER - A storage for permanent information about peers
 *
 * This source is covered by the GNU GPL, the same as all kernel sources.
 *
 * Authors: Andrey V. Savochkin <saw@msu.ru>
 */

#include <linux/module.h>
#include <linux/types.h>
#include <linux/slab.h>
#include <linux/interrupt.h>
#include <linux/spinlock.h>
#include <linux/random.h>
#include <linux/timer.h>
#include <linux/time.h>
#include <linux/kernel.h>
#include <linux/mm.h>
#include <linux/net.h>
#include <net/ip.h>
#include <net/inetpeer.h>

/*
 * Theory of operations.
 * We keep one entry for each peer IP address. The nodes contains long-living
 * information about the peer which doesn't depend on routes.
 * At this moment this information consists only of ID field for the next
 * outgoing IP packet. This field is incremented with each packet as encoded
 * in inet_getid() function (include/net/inetpeer.h).
 * At the moment of writing this notes identifier of IP packets is generated
 * to be unpredictable using this code only for packets subjected
 * (actually or potentially) to defragmentation. I.e. DF packets less than
 * PMTU in size uses a constant ID and do not use this code (see
 * ip_select_ident() in include/net/ip.h).
 *
 * Route cache entries hold references to our nodes.
 * New cache entries get references via lookup by destination IP address in
 * the avl tree. The reference is grabbed only when it's needed i.e. only
 * when we try to output IP packet which needs an unpredictable ID (see
 * __ip_select_ident() in net/ipv4/route.c).
 * Nodes are removed only when reference counter goes to 0.
 * When it's happened the node may be removed when a sufficient amount of
 * time has been passed since its last use. The less-recently-used entry can
 * also be removed if the pool is overloaded i.e. if the total amount of
 * entries is greater-or-equal than the threshold.
 *
 * Node pool is organised as an AVL tree.
 * Such an implementation has been chosen not just for fun. It's a way to
 * prevent easy and efficient DoS attacks by creating hash collisions. A huge
 * amount of long living nodes in a single hash slot would significantly delay
 * lookups performed with disabled BHs.
 *
 * Serialisation issues.
 * 1. Nodes may appear in the tree only with the pool lock held.
 * 2. Nodes may disappear from the tree only with the pool lock held
 * AND reference count being 0.
 * 3. Global variable peer_total is modified under the pool lock.
 * 4. struct inet_peer fields modification:
 * avl_left, avl_right, avl_parent, avl_height: pool lock
 * refcnt: atomically against modifications on other CPU;
 * usually under some other lock to prevent node disappearing
 * daddr: unchangeable
 * ip_id_count: atomic value (no lock needed)
 */

static struct kmem_cache *peer_cachep __read_mostly;

#define node_height(x) x->avl_height

#define peer_avl_empty ((struct inet_peer *)&peer_fake_node)
#define peer_avl_empty_rcu ((struct inet_peer __rcu __force *)&peer_fake_node)
static const struct inet_peer peer_fake_node = {
	.avl_left	= peer_avl_empty_rcu,
	.avl_right	= peer_avl_empty_rcu,
	.avl_height	= 0
}